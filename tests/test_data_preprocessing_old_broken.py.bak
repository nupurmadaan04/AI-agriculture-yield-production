"""
Unit tests for data preprocessing module.

This module contains comprehensive unit tests for all data preprocessing functions
including data loading, missing value handling, outlier detection and removal,
feature encoding, data scaling, and validation.
"""

import unittest
import pandas as pd
import numpy as np
import os
import tempfile
import shutil
from unittest.mock import patch, MagicMock
import sys

# Add src directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

# Import our preprocessing functions
from preprocessing_functions import (
    load_crop_data, filter_rice_data, check_missing_values, 
    handle_missing_values, encode_categorical_column, detect_outliers_iqr,
    remove_outliers_iqr, scale_features, split_data, validate_data_format,
    save_processed_data, complete_preprocessing_pipeline
)


class TestPreprocessingFunctions(unittest.TestCase):
    """Test cases for preprocessing functions."""
    
    def setUp(self):
        """Set up test fixtures before each test method."""
        # Create sample data for testing
        self.sample_data = pd.DataFrame({
            'Year': [2020, 2021, 2022, 2020, 2021],
            'State Name': ['State A', 'State B', 'State A', 'State C', 'State B'],
            'Dist Name': ['Dist 1', 'Dist 2', 'Dist 1', 'Dist 3', 'Dist 2'],
            'RICE AREA (1000 ha)': [100, 150, 120, 80, 200],
            'RICE PRODUCTION (1000 tons)': [300, 450, 360, 240, 600],
            'RICE YIELD (Kg per ha)': [3000, 3200, 2800, 3100, 3500]  # More variation for proper testing
        })
        
        # Create data with missing values
        self.data_with_missing = self.sample_data.copy()
        self.data_with_missing.loc[0, 'RICE AREA (1000 ha)'] = np.nan
        self.data_with_missing.loc[1, 'RICE YIELD (Kg per ha)'] = np.nan
        
        # Create data with outliers
        self.data_with_outliers = self.sample_data.copy()
        self.data_with_outliers.loc[0, 'RICE YIELD (Kg per ha)'] = 10000  # outlier
        self.data_with_outliers.loc[1, 'RICE YIELD (Kg per ha)'] = 500    # outlier
        
        # Create temporary directory for file operations
        self.temp_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        """Clean up after each test method."""
        # Remove temporary directory
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_load_data_success(self):
        """Test successful data loading."""
        # Create temporary CSV file
        test_file = os.path.join(self.temp_dir, 'test_data.csv')
        self.sample_data.to_csv(test_file, index=False)
        
        # Test loading
        result = pf.load_crop_data(test_file)
        
        self.assertIsInstance(result, pd.DataFrame)
        self.assertEqual(len(result), 5)
        self.assertEqual(list(result.columns), list(self.sample_data.columns))
    
    def test_load_data_file_not_found(self):
        """Test loading non-existent file."""
        with self.assertRaises(FileNotFoundError):
            pf.load_crop_data('/nonexistent/file.csv')
    
    def test_load_data_empty_file(self):
        """Test loading empty CSV file."""
        # Create empty CSV file
        test_file = os.path.join(self.temp_dir, 'empty.csv')
        pd.DataFrame().to_csv(test_file, index=False)
        
        with self.assertRaises(pd.errors.EmptyDataError):
            pf.load_crop_data(test_file)
    
    def test_filter_rice_data_success(self):
        """Test successful rice data filtering."""
        result = pf.filter_rice_data(self.sample_data)
        
        expected_columns = [
            'Year', 'State Name', 'Dist Name', 
            'RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)', 
            'RICE YIELD (Kg per ha)'
        ]
        
        self.assertEqual(list(result.columns), expected_columns)
        self.assertEqual(len(result), 5)
    
    def test_filter_rice_data_missing_columns(self):
        """Test rice data filtering with missing columns."""
        incomplete_data = pd.DataFrame({
            'Year': [2020, 2021],
            'State Name': ['State A', 'State B']
            # Missing required columns
        })
        
        with self.assertRaises(KeyError) as context:
            pf.filter_rice_data(incomplete_data)
        
        self.assertIn('Missing required columns', str(context.exception))
    
    def test_handle_missing_values_drop(self):
        """Test handling missing values with drop strategy."""
        result = pf.handle_missing_values(self.data_with_missing, strategy='drop')
        
        # Should have 3 rows after dropping rows with missing values
        self.assertEqual(len(result), 3)
        self.assertFalse(result.isnull().any().any())
    
    def test_handle_missing_values_fill_mean(self):
        """Test handling missing values with mean filling strategy."""
        result = pf.handle_missing_values(self.data_with_missing, strategy='fill_mean')
        
        # Should have same number of rows
        self.assertEqual(len(result), 5)
        
        # Numeric columns should not have missing values
        numeric_cols = result.select_dtypes(include=[np.number]).columns
        self.assertFalse(result[numeric_cols].isnull().any().any())
    
    def test_handle_missing_values_fill_median(self):
        """Test handling missing values with median filling strategy."""
        result = pf.handle_missing_values(self.data_with_missing, strategy='fill_median')
        
        # Should have same number of rows
        self.assertEqual(len(result), 5)
        
        # Numeric columns should not have missing values
        numeric_cols = result.select_dtypes(include=[np.number]).columns
        self.assertFalse(result[numeric_cols].isnull().any().any())
    
    def test_handle_missing_values_invalid_strategy(self):
        """Test handling missing values with invalid strategy."""
        with self.assertRaises(ValueError):
            pf.handle_missing_values(self.sample_data, strategy='invalid_strategy')
    
    def test_encode_categorical_features_success(self):
        """Test successful categorical feature encoding."""
        result = pf.encode_categorical_column(self.sample_data, 'State Name')
        
        # Should have new encoded column
        self.assertIn('state_name_encoded', result.columns)
        
        # Encoded column should be numeric
        self.assertTrue(pd.api.types.is_numeric_dtype(result['state_name_encoded']))
        
        # Should have same number of rows
        self.assertEqual(len(result), 5)
    
    def test_encode_categorical_features_missing_column(self):
        """Test encoding non-existent column."""
        with self.assertRaises(KeyError):
            pf.encode_categorical_column(self.sample_data, 'NonExistent Column')
    
    def test_encode_categorical_features_with_nan(self):
        """Test encoding categorical features with NaN values."""
        data_with_nan = self.sample_data.copy()
        data_with_nan.loc[0, 'State Name'] = np.nan
        
        result = pf.encode_categorical_column(data_with_nan, 'State Name')
        
        # Should handle NaN values by replacing with 'Unknown'
        self.assertIn('state_name_encoded', result.columns)
        self.assertFalse(result['state_name_encoded'].isnull().any())
    
    def test_detect_outliers_iqr_success(self):
        """Test successful outlier detection using IQR method."""
        bounds = pf.detect_outliers_iqr(self.data_with_outliers, 'RICE YIELD (Kg per ha)')
        
        # Should return dictionary with required keys
        required_keys = ['lower_bound', 'upper_bound', 'Q1', 'Q3', 'IQR']
        for key in required_keys:
            self.assertIn(key, bounds)
        
        # Values should be numeric
        for key in required_keys:
            self.assertIsInstance(bounds[key], (int, float))
        
        # IQR should be positive
        self.assertGreater(bounds['IQR'], 0)
    
    def test_detect_outliers_iqr_missing_column(self):
        """Test outlier detection with non-existent column."""
        with self.assertRaises(KeyError):
            pf.detect_outliers_iqr(self.sample_data, 'NonExistent Column')
    
    def test_detect_outliers_iqr_non_numeric_column(self):
        """Test outlier detection with non-numeric column."""
        with self.assertRaises(ValueError):
            pf.detect_outliers_iqr(self.sample_data, 'State Name')
    
    def test_remove_outliers_success(self):
        """Test successful outlier removal."""
        # Remove outliers using IQR method
        result = pf.remove_outliers_iqr(self.data_with_outliers, 'RICE YIELD (Kg per ha)')
        
        # Should have fewer rows than original
        self.assertLess(len(result), len(self.data_with_outliers))
        
        # Verify outliers were removed (should not contain extreme values)
        yield_values = result['RICE YIELD (Kg per ha)']
        self.assertNotIn(10000, yield_values.values)  # High outlier
        self.assertNotIn(500, yield_values.values)    # Low outlier
    
    def test_scale_features_success(self):
        """Test successful feature scaling."""
        # Prepare training and test data
        X_train = self.sample_data[['Year', 'RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)']]
        X_test = X_train.iloc[:2].copy()  # Use first 2 rows as test
        
        X_train_scaled, X_test_scaled, scaler = pf.scale_features(X_train, X_test)
        
        # Should return numpy arrays
        self.assertIsInstance(X_train_scaled, np.ndarray)
        self.assertIsInstance(X_test_scaled, np.ndarray)
        
        # Should have same shape as input
        self.assertEqual(X_train_scaled.shape, X_train.shape)
        self.assertEqual(X_test_scaled.shape, X_test.shape)
        
        # Scaled data should have approximately zero mean and unit variance
        np.testing.assert_allclose(X_train_scaled.mean(axis=0), 0, atol=1e-10)
        np.testing.assert_allclose(X_train_scaled.std(axis=0), 1, atol=1e-10)
    
    def test_scale_features_train_only(self):
        """Test feature scaling with training data only."""
        X_train = self.sample_data[['Year', 'RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)']]
        
        X_train_scaled, X_test_scaled, scaler = pf.scale_features(X_train)
        
        self.assertIsInstance(X_train_scaled, np.ndarray)
        self.assertIsNone(X_test_scaled)
    
    def test_scale_features_empty_data(self):
        """Test feature scaling with empty data."""
        empty_df = pd.DataFrame()
        
        with self.assertRaises(ValueError):
            pf.scale_features(empty_df)
    
    def test_split_data_success(self):
        """Test successful data splitting."""
        X = self.sample_data[['Year', 'RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)']]
        y = self.sample_data['RICE YIELD (Kg per ha)']
        
        X_train, X_test, y_train, y_test = pf.split_data(X, y, test_size=0.4, random_state=42)
        
        # Check shapes
        self.assertEqual(len(X_train), 3)  # 60% of 5
        self.assertEqual(len(X_test), 2)   # 40% of 5
        self.assertEqual(len(y_train), 3)
        self.assertEqual(len(y_test), 2)
        
        # Check that split is consistent
        self.assertEqual(len(X_train), len(y_train))
        self.assertEqual(len(X_test), len(y_test))
    
    def test_split_data_invalid_test_size(self):
        """Test data splitting with invalid test size."""
        X = self.sample_data[['Year']]
        y = self.sample_data['RICE YIELD (Kg per ha)']
        
        with self.assertRaises(ValueError):
            pf.split_data(X, y, test_size=1.5)  # Invalid test_size > 1
        
        with self.assertRaises(ValueError):
            pf.split_data(X, y, test_size=0)    # Invalid test_size = 0
    
    def test_split_data_mismatched_lengths(self):
        """Test data splitting with mismatched X and y lengths."""
        X = self.sample_data[['Year']]
        y = self.sample_data['RICE YIELD (Kg per ha)'].iloc[:3]  # Different length
        
        with self.assertRaises(ValueError):
            pf.split_data(X, y)
    
    def test_split_data_empty_data(self):
        """Test data splitting with empty data."""
        X = pd.DataFrame()
        y = pd.Series()
        
        with self.assertRaises(ValueError):
            pf.split_data(X, y)
    
    def test_validate_data_format_success(self):
        """Test successful data format validation."""
        validation_summary = pf.validate_data_format(self.sample_data)
        
        # Check required keys
        required_keys = [
            'shape', 'columns', 'dtypes', 'missing_values', 'duplicate_rows', 'memory_usage_mb'
        ]
        
        for key in required_keys:
            self.assertIn(key, validation_summary)
        
        # Check specific values
        self.assertEqual(validation_summary['shape'], (5, 6))
        self.assertEqual(len(validation_summary['columns']), 6)
        self.assertIsInstance(validation_summary['memory_usage_mb'], float)
    
    def test_validate_data_format_with_issues(self):
        """Test data format validation with data quality issues."""
        # Create data with various issues
        problematic_data = self.sample_data.copy()
        problematic_data.loc[0, 'RICE YIELD (Kg per ha)'] = -100  # Negative yield
        problematic_data.loc[1, 'RICE AREA (1000 ha)'] = 0        # Zero area
        problematic_data.loc[2, 'RICE PRODUCTION (1000 tons)'] = 0  # Zero production
        # Add a duplicate row with DIFFERENT values from the negative yield row
        duplicate_row = problematic_data.iloc[3:4].copy()  # Use row 3 instead of row 0
        problematic_data = pd.concat([problematic_data, duplicate_row], ignore_index=True)  # Duplicate row
        
        validation_summary = pf.validate_data_format(problematic_data)
        
        # Should detect issues
        self.assertEqual(validation_summary['negative_yield_count'], 1)  # Only one negative yield
        self.assertEqual(validation_summary['zero_area_count'], 1)
        self.assertEqual(validation_summary['zero_production_count'], 1)
        self.assertEqual(validation_summary['duplicate_rows'], 1)


class TestPreprocessingPipeline(unittest.TestCase):
    """Test cases for the complete preprocessing pipeline."""
    
    def setUp(self):
        """Set up test fixtures."""
        # Create sample data
        self.sample_data = pd.DataFrame({
            'Year': [2020, 2021, 2022, 2020, 2021, 2022, 2020],
            'State Name': ['State A', 'State B', 'State A', 'State C', 'State B', 'State A', 'State D'],
            'Dist Name': ['Dist 1', 'Dist 2', 'Dist 1', 'Dist 3', 'Dist 2', 'Dist 1', 'Dist 4'],
            'RICE AREA (1000 ha)': [100, 150, 120, 80, 200, 110, 90],
            'RICE PRODUCTION (1000 tons)': [300, 450, 360, 240, 600, 330, 270],
            'RICE YIELD (Kg per ha)': [3000, 3000, 3000, 3000, 3000, 10000, 500],  # Include outliers
            'OTHER CROP': [1, 2, 3, 4, 5, 6, 7]  # Additional column
        })
        
        # Create temporary directory
        self.temp_dir = tempfile.mkdtemp()
        self.test_file = os.path.join(self.temp_dir, 'test_crops_data.csv')
        self.sample_data.to_csv(self.test_file, index=False)
    
    def tearDown(self):
        """Clean up after tests."""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_preprocessing_pipeline_success(self):
        """Test successful execution of preprocessing pipeline."""
        # Create output file path
        output_file = os.path.join(self.temp_dir, 'processed_rice_data.csv')
        
        # Run complete preprocessing pipeline
        processing_summary = pf.complete_preprocessing_pipeline(self.test_file, output_file)
        
        # Check processing summary
        self.assertIn('original_shape', processing_summary)
        self.assertIn('final_shape', processing_summary)
        self.assertIn('rows_removed', processing_summary)
        self.assertIn('validation_summary', processing_summary)
        
        # Check that outliers were removed
        self.assertLess(processing_summary['final_shape'][0], processing_summary['original_shape'][0])
        
        # Check that output file was created
        self.assertTrue(os.path.exists(output_file))
        
        # Load and verify processed data
        processed_data = pd.read_csv(output_file)
        self.assertIsInstance(processed_data, pd.DataFrame)
        self.assertGreater(len(processed_data), 0)
        self.assertIn('state_name_encoded', processed_data.columns)
    
    def test_complete_pipeline_components(self):
        """Test individual components work in sequence."""
        # Load data
        data = pf.load_crop_data(self.test_file)
        self.assertIsInstance(data, pd.DataFrame)
        
        # Filter rice data
        rice_data = pf.filter_rice_data(data)
        self.assertEqual(len(rice_data.columns), 6)
        
        # Handle missing values
        clean_data = pf.handle_missing_values(rice_data, strategy='drop')
        self.assertFalse(clean_data.isnull().any().any())
        
        # Encode categorical variables
        encoded_data = pf.encode_categorical_column(clean_data, 'State Name')
        self.assertIn('state_name_encoded', encoded_data.columns)
        
        # Remove outliers
        final_data = pf.remove_outliers_iqr(encoded_data, 'RICE YIELD (Kg per ha)')
        self.assertLess(len(final_data), len(encoded_data))


class TestEdgeCases(unittest.TestCase):
    """Test cases for edge cases and error conditions."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """Clean up after tests."""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_very_small_dataset(self):
        """Test preprocessing with very small dataset."""
        small_data = pd.DataFrame({
            'Year': [2020],
            'State Name': ['State A'],
            'Dist Name': ['Dist 1'],
            'RICE AREA (1000 ha)': [100],
            'RICE PRODUCTION (1000 tons)': [300],
            'RICE YIELD (Kg per ha)': [3000]
        })
        
        # Should handle small dataset gracefully
        result = pf.filter_rice_data(small_data)
        self.assertEqual(len(result), 1)
        
        # Outlier detection should still work
        bounds = pf.detect_outliers_iqr(small_data, 'RICE YIELD (Kg per ha)')
        self.assertIsInstance(bounds, dict)
    
    def test_all_identical_values(self):
        """Test preprocessing with all identical values."""
        identical_data = pd.DataFrame({
            'Year': [2020, 2020, 2020],
            'State Name': ['State A', 'State A', 'State A'],
            'Dist Name': ['Dist 1', 'Dist 1', 'Dist 1'],
            'RICE AREA (1000 ha)': [100, 100, 100],
            'RICE PRODUCTION (1000 tons)': [300, 300, 300],
            'RICE YIELD (Kg per ha)': [3000, 3000, 3000]
        })
        
        # Should handle identical values
        bounds = pf.detect_outliers_iqr(identical_data, 'RICE YIELD (Kg per ha)')
        self.assertEqual(bounds['IQR'], 0)  # IQR should be 0 for identical values
        
        # Scaling should handle identical values
        X = identical_data[['RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)']]
        try:
            X_scaled, _, scaler = pf.scale_features(X)
            # Should complete without error
            self.assertIsInstance(X_scaled, np.ndarray)
        except Exception as e:
            # Some scalers may have issues with zero variance
            self.assertIn('variance', str(e).lower())
    
    def test_extreme_outliers(self):
        """Test preprocessing with extreme outliers."""
        extreme_data = pd.DataFrame({
            'Year': [2020, 2021, 2022],
            'State Name': ['State A', 'State B', 'State C'],
            'Dist Name': ['Dist 1', 'Dist 2', 'Dist 3'],
            'RICE AREA (1000 ha)': [100, 150, 1000000],  # Extreme outlier
            'RICE PRODUCTION (1000 tons)': [300, 450, 500],
            'RICE YIELD (Kg per ha)': [3000, 3200, 0.001]  # Extreme outlier
        })
        
        # Should detect extreme outliers
        bounds = pf.detect_outliers_iqr(extreme_data, 'RICE AREA (1000 ha)')
        self.assertGreater(bounds['outlier_count'], 0)
        
        # Should remove extreme outliers
        cleaned = pf.remove_outliers_iqr(extreme_data, 'RICE AREA (1000 ha)')
        self.assertLess(len(cleaned), len(extreme_data))
        identical_data = pd.DataFrame({
            'Year': [2020, 2020, 2020],
            'State Name': ['State A', 'State A', 'State A'],
            'Dist Name': ['Dist 1', 'Dist 1', 'Dist 1'],
            'RICE AREA (1000 ha)': [100, 100, 100],
            'RICE PRODUCTION (1000 tons)': [300, 300, 300],
            'RICE YIELD (Kg per ha)': [3000, 3000, 3000]
        })
        
        # Should handle identical values
        bounds = self.preprocessor.detect_outliers_iqr(identical_data, 'RICE YIELD (Kg per ha)')
        self.assertEqual(bounds['iqr'], 0)  # IQR should be 0 for identical values
        
        # Scaling should still work (though result will be zeros)
        X = identical_data[['RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)']]
        X_scaled, _ = self.preprocessor.scale_features(X)
        self.assertEqual(X_scaled.shape, X.shape)
    
    def test_extreme_outliers(self):
        """Test handling of extreme outliers."""
        extreme_data = pd.DataFrame({
            'Year': [2020, 2021, 2022],
            'State Name': ['State A', 'State B', 'State C'],
            'Dist Name': ['Dist 1', 'Dist 2', 'Dist 3'],
            'RICE AREA (1000 ha)': [100, 150, 120],
            'RICE PRODUCTION (1000 tons)': [300, 450, 360],
            'RICE YIELD (Kg per ha)': [3000, 1000000, 3000]  # Extreme outlier
        })
        
        # Should detect and handle extreme outliers
        bounds = self.preprocessor.detect_outliers_iqr(extreme_data, 'RICE YIELD (Kg per ha)')
        result = self.preprocessor.remove_outliers(extreme_data, 'RICE YIELD (Kg per ha)', bounds)
        
        # Should remove the extreme outlier
        self.assertEqual(len(result), 2)
        self.assertNotIn(1000000, result['RICE YIELD (Kg per ha)'].values)


if __name__ == '__main__':
    # Create test suite
    test_suite = unittest.TestSuite()
    
    # Add test cases
    test_suite.addTest(unittest.makeSuite(TestPreprocessingFunctions))
    test_suite.addTest(unittest.makeSuite(TestPreprocessingPipeline))
    test_suite.addTest(unittest.makeSuite(TestEdgeCases))
    
    # Run tests with detailed output
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # Print summary
    print(f"\n{'='*50}")
    print(f"TEST SUMMARY")
    print(f"{'='*50}")
    print(f"Tests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")
    print(f"Success rate: {((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100):.1f}%")
    
    if result.failures:
        print(f"\nFAILURES:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print(f"\nERRORS:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
